{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Loading MNIST Dataset in pytorch.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"zl0BJKYtJPyw","colab_type":"text"},"source":["### Mounting your GDrive\n","\n","Mount your google drive so that you'll be able to access the files on your drive."]},{"cell_type":"code","metadata":{"id":"Sc9sKkcHVutD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":124},"executionInfo":{"status":"ok","timestamp":1599576079582,"user_tz":-480,"elapsed":23720,"user":{"displayName":"Shaun Tieon","photoUrl":"","userId":"14001088521975559006"}},"outputId":"151b9fc0-1ef7-411e-c6e8-f554a3c24a33"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tDfy-a-WJb7_","colab_type":"text"},"source":["## Importing necessary module for loading own dataset"]},{"cell_type":"code","metadata":{"id":"Pybn38n8bd4M","colab_type":"code","colab":{}},"source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","import matplotlib.pyplot as plt\n","\n","from torch.utils.data import random_split\n","from torch.utils.data import DataLoader"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e33-YFkQoLgr","colab_type":"text"},"source":["We will use MNIST images downloaded from [here](http://yann.lecun.com/exdb/mnist/). We load only a small sample of the MNIST images just to show you guys how you can load your own custom images for training your model.\n","\n","Images should be stored in the following format:\n","\n","Folder\n","\n","    -- Train (folder)\n","        -- 0 (folder class label)\n","          1.jpg\n","          2.jpg\n","          3.jpg\n","        -- 1 (folder class label)\n","          1.jpg\n","          2.jpg\n","\n","        -- 2 (folder class label)\n","          1.jpg\n","          2.jpg\n","\n","There are other ways to load custom datasets in other formats, but we recommend sorting the dataset in the following format for ease of loading. Please refer [here](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html) for more information.\n","\n","We will use the `.ImageFolder` function here."]},{"cell_type":"code","metadata":{"id":"M6CADZpsbyT_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1599576087532,"user_tz":-480,"elapsed":4775,"user":{"displayName":"Shaun Tieon","photoUrl":"","userId":"14001088521975559006"}},"outputId":"2d3a0d03-c40b-466f-f6bb-973ceee6bee0"},"source":["data_path = '/content/drive/My Drive/Colab Notebooks/ML201+/MNIST Dataset/trainingSample/' # Set this to your datapath\n","train_dataset = torchvision.datasets.ImageFolder(\n","        root=data_path,\n","        transform=transforms.ToTensor()\n","    )\n","\n","# Print out shape of tensor and labels\n","tensor_image, label = train_dataset[0]\n","print(tensor_image.shape, label)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["torch.Size([3, 28, 28]) 0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OGGi2mKxKRpt","colab_type":"text"},"source":["### Visualise Tensors"]},{"cell_type":"markdown","metadata":{"id":"6qySEe7blxNQ","colab_type":"text"},"source":["[`.permute`](https://stackoverflow.com/questions/53623472/how-do-i-display-a-single-image-in-pytorch/53633017) changes the channel to the last dimension, allowing the image to display when using `plt.imshow`."]},{"cell_type":"code","metadata":{"id":"hkXcL1_uj2F7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":283},"executionInfo":{"status":"ok","timestamp":1599576087536,"user_tz":-480,"elapsed":1930,"user":{"displayName":"Shaun Tieon","photoUrl":"","userId":"14001088521975559006"}},"outputId":"575a9ae7-18ba-4751-b060-a06ce761d065"},"source":["# Use .permute() to put channels as the last dimension, used for RGB tensor with 3 channels.\n","plt.imshow(tensor_image.permute(1, 2, 0))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7fccae6b90b8>"]},"metadata":{"tags":[]},"execution_count":5},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"8-PlBvlcl9M6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1599576090791,"user_tz":-480,"elapsed":898,"user":{"displayName":"Shaun Tieon","photoUrl":"","userId":"14001088521975559006"}},"outputId":"a1e25c22-87b3-4e07-c1c7-0b34be745196"},"source":["from torch.utils.data import random_split\n","\n","train_ds, val_ds = random_split(train_dataset, [500, 100])\n","print(len(train_ds), len(val_ds))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["500 100\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4eZMmyvnKj_2","colab_type":"text"},"source":["Load images into `train_loader` and `val_loader` respectively."]},{"cell_type":"code","metadata":{"id":"jD4k17OWmqSC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1599576092834,"user_tz":-480,"elapsed":1103,"user":{"displayName":"Shaun Tieon","photoUrl":"","userId":"14001088521975559006"}},"outputId":"bd0e3863-1132-42eb-d8b4-2f33a95cf07d"},"source":["from torch.utils.data import DataLoader\n","\n","batch_size = 64\n","\n","train_loader = DataLoader(train_ds, batch_size, shuffle=True)\n","val_loader = DataLoader(val_ds, batch_size)\n","\n","print(train_loader)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["<torch.utils.data.dataloader.DataLoader object at 0x7fccae60fac8>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2SnGj_9UnolJ","colab_type":"text"},"source":["### Combining all into a single function"]},{"cell_type":"code","metadata":{"id":"_sEfiP1Kmyig","colab_type":"code","colab":{}},"source":["def load_dataset(data_path, batch_size):\n","    dataset = torchvision.datasets.ImageFolder(\n","        root=data_path,\n","        transform=transforms.ToTensor()\n","    )\n","\n","    train_ds, val_ds = random_split(dataset, [500,100]) # Manually define split\n","\n","    train_loader = DataLoader(\n","        train_ds,\n","        batch_size=64,  \n","        shuffle=True)\n","    \n","    val_loader = DataLoader(\n","        val_ds,\n","        batch_size=64)\n","\n","    return train_loader, val_loader"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i3_e8ngHqlTR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":55},"executionInfo":{"status":"ok","timestamp":1599400423131,"user_tz":-480,"elapsed":1080,"user":{"displayName":"Shaun Tieon","photoUrl":"","userId":"14001088521975559006"}},"outputId":"1fa57545-29de-4061-fcd5-261887c0c3f6"},"source":["load_dataset('/content/drive/My Drive/Colab Notebooks/ML201+/MNIST Dataset/trainingSample/',64)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["<torch.utils.data.dataloader.DataLoader object at 0x7f2befe2fe80> <torch.utils.data.dataloader.DataLoader object at 0x7f2befe8ce80>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"iZuNSFfwK0X5","colab_type":"text"},"source":["This train_loader and val_loader can then be passed into the `fit` function defined in the other notebook. Now, you can try creating your own dataset and loading them yourselves!!"]},{"cell_type":"code","metadata":{"id":"zqQDz9D-LZB1","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}